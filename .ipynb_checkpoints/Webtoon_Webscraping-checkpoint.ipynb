{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd46181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c83e779",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Webscrapping to get webtoons mangas views, rating, genre, chapters,summary\n",
    "\n",
    "# Function to extract title id\n",
    "def get_title_id(link):\n",
    "    try:\n",
    "        title_id = link.split(\"?title_no=\")[-1]\n",
    "        \n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        title_id = \"\"\n",
    "\n",
    "    return title_id\n",
    "    \n",
    "# Function to extract manga title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find('h1', class_='subj').get_text(\" \", strip=True)\n",
    "        clean_title = title.replace(\"#\", \"\").replace(\"â€™\", \"'\").strip()\n",
    "        \n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        clean_title = \"Not Avaliable\"\n",
    "\n",
    "    return clean_title\n",
    "\n",
    "# Function to extract manga genre\n",
    "def get_genre(soup):\n",
    "    try:\n",
    "        genre = soup.find(\"h2\", attrs={\"class\":'genre'}).string.strip()\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        genre = \"Not Available\"\n",
    "\n",
    "    return genre\n",
    "\n",
    "\n",
    "# Function to extract manga authors\n",
    "def get_authors(soup):\n",
    "    try:\n",
    "        # Extract author names and join into a string\n",
    "        authors = \", \".join([h3.text.strip() for h3 in soup.find_all(\"h3\", class_=\"title\")])\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        authors = \"Not Available\"\n",
    "\n",
    "    return authors\n",
    "\n",
    "\n",
    "# Function to extract the released days\n",
    "def get_weekdays(soup):\n",
    "    try:\n",
    "        weekdays = soup.find(\"p\", attrs={\"class\":'day_info'}).text\n",
    "        if weekdays != \"COMPLETED\":\n",
    "            weekdays = weekdays.split(\" \")\n",
    "            week = weekdays[1].strip()\n",
    "        else:\n",
    "            week = \"Released\"\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        week = \"Not Available\"\n",
    "\n",
    "    return week\n",
    "    \n",
    "# Function to extract chapters count\n",
    "def get_length(soup):\n",
    "    try:\n",
    "        chapters = soup.find(\"span\", attrs={\"class\": \"tx\"})\n",
    "        if chapters and chapters.string:\n",
    "            chapters = chapters.string.strip().replace(\"#\", \"\")\n",
    "            clean_chapter = int(chapters) if chapters.isdigit() else None\n",
    "        else:\n",
    "            clean_chapter = None\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        clean_chapter = None  # Handle missing elements and invalid conversion\n",
    "\n",
    "    return clean_chapter\n",
    "\n",
    "# Function to extract subscriber count\n",
    "def get_subscriber_count(soup):\n",
    "    try:\n",
    "        subscriber_count = soup.find_all(\"em\", attrs={\"class\":'cnt'})\n",
    "        subscriber = subscriber_count[1].string.strip()\n",
    "        if subscriber.endswith(\"M\"):\n",
    "            subscriber = float(subscriber[:-1]) * 1000000  # Remove 'M' and multiply\n",
    "        else:\n",
    "            subscriber = float(subscriber)  # Convert to float if no 'M'\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        subscriber = None\n",
    "\n",
    "    return subscriber\n",
    "\n",
    "# Function to extract rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating = soup.find(\"em\", attrs={\"id\":'_starScoreAverage'})\n",
    "        if rating:  # Ensure the element exists\n",
    "            rating = float(rating.string.strip())  # Convert to float\n",
    "        else:\n",
    "            rating = None  # Handle case when element is missing\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        rating = None\n",
    "\n",
    "    return rating\n",
    "\n",
    "# Function to extract views count\n",
    "def get_views_count(soup):\n",
    "    try:\n",
    "        views_count = soup.find_all(\"em\", attrs={\"class\":'cnt'})\n",
    "        views = views_count[0].string.strip()\n",
    "        if views.endswith(\"M\"):\n",
    "            views = float(views[:-1]) * 1000000  # Remove 'M' and multiply\n",
    "        else:\n",
    "            views = float(views)  # Convert to float if no 'M'\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        views = None\n",
    "\n",
    "    return views\n",
    "\n",
    "# Function to extract the status of manga\n",
    "def get_status(soup):\n",
    "    try:\n",
    "        weekdays = soup.find(\"p\", attrs={'class':\"day_info\"}).text\n",
    "        hiatus = soup.find(\"div\", attrs={'class':\"detail_paywall\"})\n",
    "        pause = soup.find(\"span\",{'class':\"subj\"})\n",
    "        p = \"Finale\" in pause.text\n",
    "        if hiatus is not None or p:\n",
    "            status = \"HIATUS\"\n",
    "        elif weekdays != \"COMPLETED\":\n",
    "            status = \"ONGOING\"\n",
    "        else:\n",
    "            status = \"COMPLETED\"\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        status = \"Not Available\"\n",
    "\n",
    "    return status\n",
    "\n",
    "# Function to extract the status of manga\n",
    "def get_daily_pass(soup):\n",
    "    try:\n",
    "        weekdays = soup.find(\"p\", attrs={'class':\"day_info\"}).text\n",
    "        hiatus = soup.find(\"div\", attrs={'class':\"detail_paywall\"})\n",
    "        pause = soup.find(\"span\",{'class':\"subj\"})\n",
    "        p = \"Finale\" in pause.text\n",
    "        if hiatus is not None or p:\n",
    "            status = \"HIATUS\"\n",
    "        elif weekdays != \"COMPLETED\":\n",
    "            status = \"ONGOING\"\n",
    "        else:\n",
    "            status = \"COMPLETED\"\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        status = \"Not Available\"\n",
    "\n",
    "    return status\n",
    "\n",
    "# Function to extract manga summary\n",
    "def get_synopsis(soup):\n",
    "    try:\n",
    "        summary = soup.find(\"p\", attrs={\"class\":'summary'}).string.strip()\n",
    "\n",
    "    except (AttributeError, ValueError, TypeError):\n",
    "        summary = \"Not Avaliable\"\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32089985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dodle\\AppData\\Local\\Temp\\ipykernel_28372\\3301861056.py:45: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  webtoon_df['title'].replace('', np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # add your user agent \n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "\n",
    "    # The webpage URL\n",
    "    URL = \"https://www.webtoons.com/en/originals\"\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = re.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Soup Object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Initializing a dictionary to extract fields\n",
    "    d = {\"title_id\":[], \"title\":[], \"genre\":[], \"authors\":[], \"weekdays\":[], \"length\":[], \"subscriber\":[], \"rating\":[], \"views\":[], \"likes\":[], \"status\":[], \"daily_pass\":[], \"synopsis\":[]}\n",
    "\n",
    "    # Extracting likes and status\n",
    "    d['likes'] = [\n",
    "    float(p.text[:-1]) * 1000000 if p.text.endswith(\"M\") else float(p.text) \n",
    "    for p in soup.find_all('em', class_='grade_num')\n",
    "    ]\n",
    "\n",
    "    # Fetch links as List of Tag Objects\n",
    "    links = soup.find_all(\"a\", attrs={'class':'card_item'})\n",
    "\n",
    "    # Store the links\n",
    "    links_list = []\n",
    "\n",
    "    # Loop for extracting links from Tag Objects\n",
    "    for link in links:\n",
    "            links_list.append(link.get('href'))\n",
    "    \n",
    "    # Loop for extracting product details from each link \n",
    "    for link in links_list:\n",
    "        d['title_id'].append(get_link_id(link))\n",
    "        \n",
    "        new_webpage = re.get(link, headers=HEADERS)\n",
    "\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        # Function calls to display all necessary product information\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['genre'].append(get_genre(new_soup))\n",
    "        d['authors'].append(get_authors(new_soup))\n",
    "        d['weekdays'].append(get_weekdays(new_soup))\n",
    "        d['length'].append(get_length(new_soup))\n",
    "        d['subscriber'].append(get_subscriber_count(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['views'].append(get_views_count(new_soup))\n",
    "        \n",
    "        d['daily_pass'].append(get_daily_pass(new_soup))\n",
    "        d['synopsis'].append(get_synopsis(new_soup))\n",
    "\n",
    "    \n",
    "    webtoon_df = pd.DataFrame.from_dict(d)\n",
    "    webtoon_df.to_csv(\"webtoon_data.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8722f46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>weekdays</th>\n",
       "      <th>length</th>\n",
       "      <th>subscriber</th>\n",
       "      <th>rating</th>\n",
       "      <th>views</th>\n",
       "      <th>status</th>\n",
       "      <th>synopsis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love 4 a Walk</td>\n",
       "      <td>Romance</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>48</td>\n",
       "      <td>2M</td>\n",
       "      <td>9.77</td>\n",
       "      <td>61.4M</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>Pam's heart has been broken one too many times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Remarried Empress</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>SUNDAY</td>\n",
       "      <td>204</td>\n",
       "      <td>4.4M</td>\n",
       "      <td>9.81</td>\n",
       "      <td>495M</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>Navier Ellie Trovi was an empress perfect in e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maybe Meant to Be</td>\n",
       "      <td>Romance</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>92</td>\n",
       "      <td>2.2M</td>\n",
       "      <td>9.75</td>\n",
       "      <td>153.2M</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>Jia Han, a 32-year-old freelancer with no work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Selfish Romance</td>\n",
       "      <td>Romance</td>\n",
       "      <td>FRIDAY</td>\n",
       "      <td>32</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>9.74</td>\n",
       "      <td>19.8M</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>Hyeondo and Yumin, an ordinary man and woman i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To Whom It No Longer Concerns</td>\n",
       "      <td>Drama</td>\n",
       "      <td>THURSDAY</td>\n",
       "      <td>34</td>\n",
       "      <td>1.4M</td>\n",
       "      <td>9.43</td>\n",
       "      <td>24.2M</td>\n",
       "      <td>ONGOING</td>\n",
       "      <td>Exploited by her brother, betrayed by her sist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    genre  weekdays length subscriber rating  \\\n",
       "0                  Love 4 a Walk  Romance    FRIDAY     48         2M   9.77   \n",
       "1          The Remarried Empress  Fantasy    SUNDAY    204       4.4M   9.81   \n",
       "2              Maybe Meant to Be  Romance    FRIDAY     92       2.2M   9.75   \n",
       "3                Selfish Romance  Romance    FRIDAY     32       1.2M   9.74   \n",
       "4  To Whom It No Longer Concerns    Drama  THURSDAY     34       1.4M   9.43   \n",
       "\n",
       "    views   status                                           synopsis  \n",
       "0   61.4M  ONGOING  Pam's heart has been broken one too many times...  \n",
       "1    495M  ONGOING  Navier Ellie Trovi was an empress perfect in e...  \n",
       "2  153.2M  ONGOING  Jia Han, a 32-year-old freelancer with no work...  \n",
       "3   19.8M  ONGOING  Hyeondo and Yumin, an ordinary man and woman i...  \n",
       "4   24.2M  ONGOING  Exploited by her brother, betrayed by her sist...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtoon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bf6d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Webscrapping to get webtoon mangas author and likes info\n",
    "\n",
    "# URL of the website you want to scrape\n",
    "URL = 'https://www.webtoons.com/en/genres/drama?sortOrder=READ_COUNT'\n",
    "\n",
    "# Headers for request\n",
    "HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/133.0.0.0 Safari/537.36','Accept-Language':'en-US, en;q=0.5'})\n",
    "\n",
    "# HTTP Request\n",
    "webpage = re.get(URL, headers = HEADERS)\n",
    "\n",
    "soup = BeautifulSoup(webpage.content, 'html.parser')\n",
    "\n",
    "d = {\"title\":[],\"author\":[],\"likes\":[]}\n",
    "d['title'] = [p.get_text().replace(\"#\", \"\").replace(\"â€™\", \"'\").strip() for p in soup.find_all('p', class_='subj')]\n",
    "d['author'] = [p.text for p in soup.find_all('p', class_='author')]\n",
    "d['likes'] = [p.text for p in soup.find_all('em', class_='grade_num')]\n",
    "\n",
    "webtoon_info_df = pd.DataFrame.from_dict(d)\n",
    "webtoon_info_df.to_csv(\"webtoon_info.csv\",header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b24756eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love 4 a Walk</td>\n",
       "      <td>Nuria Sanguino</td>\n",
       "      <td>3.6M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Remarried Empress</td>\n",
       "      <td>Alphatart / Sumpul</td>\n",
       "      <td>39.9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Whom It No Longer Concerns</td>\n",
       "      <td>LICO / fairydragon</td>\n",
       "      <td>1.8M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe Meant to Be</td>\n",
       "      <td>honeyskein / damcho</td>\n",
       "      <td>12.4M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selfish Romance</td>\n",
       "      <td>Gyogyo Park</td>\n",
       "      <td>1.4M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title               author  likes\n",
       "0                  Love 4 a Walk       Nuria Sanguino   3.6M\n",
       "1          The Remarried Empress   Alphatart / Sumpul  39.9M\n",
       "2  To Whom It No Longer Concerns   LICO / fairydragon   1.8M\n",
       "3              Maybe Meant to Be  honeyskein / damcho  12.4M\n",
       "4                Selfish Romance          Gyogyo Park   1.4M"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtoon_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6498f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging both csv files\n",
    "\n",
    "merge_df = pd.merge(webtoon_df,webtoon_info_df,on = 'title', how ='left' )\n",
    "\n",
    "merge_df.to_csv(\"Webtoon_Merged.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70c00fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         429\n",
       "genre         429\n",
       "chapters      429\n",
       "views         429\n",
       "subscriber    429\n",
       "rating        429\n",
       "day_info      429\n",
       "summary       429\n",
       "author        429\n",
       "likes         429\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e7e93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>chapters</th>\n",
       "      <th>views</th>\n",
       "      <th>subscriber</th>\n",
       "      <th>rating</th>\n",
       "      <th>day_info</th>\n",
       "      <th>summary</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love 4 a Walk</td>\n",
       "      <td>Romance</td>\n",
       "      <td>48</td>\n",
       "      <td>61.3M</td>\n",
       "      <td>2M</td>\n",
       "      <td>9.77</td>\n",
       "      <td>EVERY FRIDAY</td>\n",
       "      <td>Pam's heart has been broken one too many times...</td>\n",
       "      <td>Nuria Sanguino</td>\n",
       "      <td>3.6M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Remarried Empress</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>204</td>\n",
       "      <td>494.9M</td>\n",
       "      <td>4.4M</td>\n",
       "      <td>9.81</td>\n",
       "      <td>EVERY SUNDAY</td>\n",
       "      <td>Navier Ellie Trovi was an empress perfect in e...</td>\n",
       "      <td>Alphatart / Sumpul</td>\n",
       "      <td>39.9M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To Whom It No Longer Concerns</td>\n",
       "      <td>Drama</td>\n",
       "      <td>33</td>\n",
       "      <td>24M</td>\n",
       "      <td>1.4M</td>\n",
       "      <td>9.44</td>\n",
       "      <td>EVERY THURSDAY</td>\n",
       "      <td>Exploited by her brother, betrayed by her sist...</td>\n",
       "      <td>LICO / fairydragon</td>\n",
       "      <td>1.8M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Maybe Meant to Be</td>\n",
       "      <td>Romance</td>\n",
       "      <td>92</td>\n",
       "      <td>153.1M</td>\n",
       "      <td>2.2M</td>\n",
       "      <td>9.75</td>\n",
       "      <td>EVERY FRIDAY</td>\n",
       "      <td>Jia Han, a 32-year-old freelancer with no work...</td>\n",
       "      <td>honeyskein / damcho</td>\n",
       "      <td>12.4M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Selfish Romance</td>\n",
       "      <td>Romance</td>\n",
       "      <td>32</td>\n",
       "      <td>19.7M</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>9.74</td>\n",
       "      <td>EVERY FRIDAY</td>\n",
       "      <td>Hyeondo and Yumin, an ordinary man and woman i...</td>\n",
       "      <td>Gyogyo Park</td>\n",
       "      <td>1.4M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title    genre chapters   views subscriber rating  \\\n",
       "0                  Love 4 a Walk  Romance       48   61.3M         2M   9.77   \n",
       "1          The Remarried Empress  Fantasy      204  494.9M       4.4M   9.81   \n",
       "2  To Whom It No Longer Concerns    Drama       33     24M       1.4M   9.44   \n",
       "3              Maybe Meant to Be  Romance       92  153.1M       2.2M   9.75   \n",
       "4                Selfish Romance  Romance       32   19.7M       1.2M   9.74   \n",
       "\n",
       "         day_info                                            summary  \\\n",
       "0    EVERY FRIDAY  Pam's heart has been broken one too many times...   \n",
       "1    EVERY SUNDAY  Navier Ellie Trovi was an empress perfect in e...   \n",
       "2  EVERY THURSDAY  Exploited by her brother, betrayed by her sist...   \n",
       "3    EVERY FRIDAY  Jia Han, a 32-year-old freelancer with no work...   \n",
       "4    EVERY FRIDAY  Hyeondo and Yumin, an ordinary man and woman i...   \n",
       "\n",
       "                author  likes  \n",
       "0       Nuria Sanguino   3.6M  \n",
       "1   Alphatart / Sumpul  39.9M  \n",
       "2   LICO / fairydragon   1.8M  \n",
       "3  honeyskein / damcho  12.4M  \n",
       "4          Gyogyo Park   1.4M  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24b0fd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>chapters</th>\n",
       "      <th>views</th>\n",
       "      <th>subscriber</th>\n",
       "      <th>rating</th>\n",
       "      <th>day_info</th>\n",
       "      <th>summary</th>\n",
       "      <th>author</th>\n",
       "      <th>likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>429</td>\n",
       "      <td>15</td>\n",
       "      <td>133</td>\n",
       "      <td>263</td>\n",
       "      <td>396</td>\n",
       "      <td>156</td>\n",
       "      <td>9</td>\n",
       "      <td>429</td>\n",
       "      <td>401</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FAMILY MAN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>7</td>\n",
       "      <td>1.2M</td>\n",
       "      <td>1.1M</td>\n",
       "      <td>9.72</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>Gang-ho is a laborer at the local factory, sle...</td>\n",
       "      <td>Ilkwon Ha</td>\n",
       "      <td>1.1M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             title  genre chapters views subscriber rating   day_info  \\\n",
       "count          429    429      429   429        429    429        429   \n",
       "unique         429     15      133   263        396    156          9   \n",
       "top     FAMILY MAN  Drama        7  1.2M       1.1M   9.72  COMPLETED   \n",
       "freq             1    150       73     8         11     11        264   \n",
       "\n",
       "                                                  summary     author likes  \n",
       "count                                                 429        429   429  \n",
       "unique                                                429        401   328  \n",
       "top     Gang-ho is a laborer at the local factory, sle...  Ilkwon Ha  1.1M  \n",
       "freq                                                    1          5    11  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eba42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
